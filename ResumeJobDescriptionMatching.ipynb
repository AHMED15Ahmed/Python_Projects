{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93tA_XsZmRe",
        "outputId": "c7d5bbab-402d-4f28-d336-01cae85f8757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.9/dist-packages (0.8)\n"
          ]
        }
      ],
      "source": [
        "#intall the required library\n",
        "!pip install docx2txt\n",
        "\n",
        "import docx2txt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#https://github.com/kanishksh4rma/Resume-Scanner-for-Job-Description--using-Cosine-Similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "my_resume = docx2txt.process('Data_Engineer-resume _.docx')\n",
        "job = docx2txt.process('Data _Engineer-job-description eng.docx')"
      ],
      "metadata": {
        "id": "pXsNsy7EaBe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the resume\n",
        "print(my_resume)\n",
        "print(\"*******\"*5)\n",
        "#print the job description\n",
        "print(job)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBwlZJYtag0t",
        "outputId": "d1a14648-503e-46d7-dda9-c14bce78e3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTACT\n",
            "\n",
            "\n",
            "\n",
            "\tDurham, United Kingdom\n",
            "\n",
            "• +44 1234567890\n",
            "\n",
            "\tﬁrst.last@gmail.com\n",
            "\n",
            "\n",
            "\n",
            "SKILLS\n",
            "\n",
            "\n",
            "\n",
            "Hard Skills:\n",
            "\n",
            "\tData Warehousing\n",
            "\n",
            "\tIntegration\n",
            "\n",
            "\tApache Kafka Streaming\n",
            "\n",
            "\tScripting\n",
            "\n",
            "\tData Pipelines\n",
            "\n",
            "\tProgramming\n",
            "\n",
            "\n",
            "\n",
            "Techniques:\n",
            "\n",
            "\tDistributed Databases\n",
            "\n",
            "\tGoogle BigQuery\n",
            "\n",
            "\tExtract, Transform, Load (ETL)\n",
            "\n",
            "\n",
            "\n",
            "Tools and Software:\n",
            "\n",
            "\tPostgreSQL\n",
            "\n",
            "\tMongoDB\n",
            "\n",
            "\tApache Kafka\n",
            "\n",
            "\tSnowﬂake\n",
            "\n",
            "\n",
            "\n",
            "Languages:\n",
            "\n",
            "\tEnglish (Native)\n",
            "\n",
            "\tRomanian (Native)\n",
            "\n",
            "\tSpanish (Conversational)\n",
            "\n",
            "\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "\n",
            "\n",
            "University of New York Bachelor of Science Mathematics\n",
            "\n",
            "New York City, New York 10/2011 - 06/2014\n",
            "\n",
            "\n",
            "\n",
            "OTHER\n",
            "\n",
            "\n",
            "\n",
            "\tCertiﬁed in Data Science\n",
            "\n",
            "\tCertiﬁed Analytics Professional\n",
            "\n",
            "First Last\n",
            "\n",
            "Data Engineer\n",
            "\n",
            "\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Resume Worded, London, United Kingdom\n",
            "\n",
            "Education technology startup with 50+ employees and $100m+ annual revenue\n",
            "\n",
            "\tData Engineer\t08/2021 – Present\n",
            "\n",
            "\t\tCreated a data pipeline to consume and store 500TB of raw data weekly using Apache NiFi, Kafka, Elasticsearch, Redis, Python, and Go.\n",
            "\n",
            "\t\tDeveloped an analytics platform for 20+ stock exchanges with real-time dashboards in ReactJS/Redux that display trade volume by currency pair, user activity, and other vital metrics.\n",
            "\n",
            "\t\tExecuted anomaly detection algorithms to detect distinctive trading patterns across 30+ FX platforms based on historical data from API and the web.\n",
            "\n",
            "\t\tDesigned a multi-user, multi-database application for 10+ clients with a data processing requirement of 1M records.\n",
            "\n",
            "Polyhire, London, United Kingdom\n",
            "\n",
            "NYSE-listed recruitment and employer branding company\n",
            "\n",
            "\tAnalytics Consultant\t10/2019 – 07/2021\n",
            "\n",
            "\t\tDevised a methodology that allowed 200+ clients to prioritize vital analytics requirements and convert them into actionable tasks within a 3-day deadline.\n",
            "\n",
            "\t\tOverhauled the ERP system at Polyhire to sustain a full range of high-volume analytics, boosting monthly revenues by 59% YoY.\n",
            "\n",
            "\t\tConstructed consumer sentiment using multivariate statistical techniques, search engine optimizers (SEOs), and stock market indexes; improved Q1 2020 sales forecasting outputs by 70%.\n",
            "\n",
            "\tDetermined optimal business patterns based on data analysis models and redeﬁned business strategy, which yielded 95% ROI values beyond industry averages.\n",
            "\n",
            "Growthsi, London, United Kingdom & Barcelona, Spain\n",
            "\n",
            "A software company that sells call center technologies\n",
            "\n",
            "\tETL Developer\t11/2018 – 09/2019\n",
            "\n",
            "\t\tOverhauled reporting ETL improvements that saved Growthsi $15K quarterly and assisted the change management unit in implementing the solution.\n",
            "\n",
            "\t\tAnalyzed ETL process failures, data anomalies, and data warehousing issues identiﬁed by 50+ developers and 300+ end-users.\n",
            "\n",
            "\t\tPartnered with 20+ business analysts and 10+ DBAs to gather requirements, business analysis, and design of data marts.\n",
            "\n",
            "\t\tDeveloped 140+ reports utilizing Microsoft SQL Server 2008 R2, which reduced development cycle time by 60% and provided substantial business value.\n",
            "\n",
            "\n",
            "\n",
            "PREVIOUS EXPERIENCE\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\tCloud Architect, ABC Company, London, UK\t06/2017 – 10/2018 Big Data Developer, XYZ Company, New York, USA\t01/2016 – 05/2017 Business Intelligence Analyst (Internship), ABC, New York, USA  07/2014 – 12/2015\n",
            "***********************************\n",
            "The Banque Centrale Populaire is recruiting a Data Engineer to join the Data Engineering, Data Mining & Delivery Department of the PTIOG, based in Casablanca.\n",
            "\n",
            "\n",
            "\n",
            "The Data Engineer will be responsible for acting as a Tech Lead within the Data Engineering team for the industrialization of DataLake solutions.\n",
            "\n",
            "\n",
            "\n",
            "Job Duties:\n",
            "\n",
            "Implement the necessary mechanisms to capture the data from the operating system and the industrialization of technical solutions from the ingestion of the data, modeling and exposure of the Data for the end user.\n",
            "\n",
            "Design and develop artificial intelligence and machine learning to maintain and improve existing AI systems\n",
            "\n",
            "Work closely with functional stakeholders and Run teams to ensure that development and deployment processes are efficient and aligned with requirements\n",
            "\n",
            "Keeping an eye on Data technology trends\n",
            "\n",
            "Ensure the transfer of skills on Data solutions to the benefit of DATA platform users\n",
            "\n",
            "\n",
            "\n",
            "Required skills and/or qualities:\n",
            "\n",
            "Good knowledge of data manipulation tools (SQL, noSQL, BI, Python, SPARk ...)\n",
            "\n",
            "Familiarity with Agile methodologies\n",
            "\n",
            "Proposal force of DATA solution respecting the development, deployment and continuous improvement standards.\n",
            "\n",
            "Analytical mind\n",
            "\n",
            "Initiative and leadership\n",
            "\n",
            "Autonomy and team spirit\n",
            "\n",
            "\n",
            "\n",
            "Desired area of excellence:\n",
            "\n",
            "DATA Engineering\n",
            "\n",
            "Machine learning\n",
            "\n",
            "Big data\n",
            "\n",
            "\n",
            "\n",
            "Profile Wanted:\n",
            "\n",
            "Professional experience of 5 years or more\n",
            "\n",
            "\n",
            "\n",
            "Academic Training:\n",
            "\n",
            "Bac+5 Engineering schools or equivalent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a list of text\n",
        "\n",
        "text = [my_resume,job]\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(text)"
      ],
      "metadata": {
        "id": "Oj0j5cLPazrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(my_resume))\n",
        "len(job)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKRiuUMNtVOT",
        "outputId": "571e5c21-27ff-42ba-eb8d-5b4395444c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3103\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1465"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cosine similarity \n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#print similarity score\n",
        "\n",
        "print('Similarity score : ',cosine_similarity(count_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfEWz8q9bJip",
        "outputId": "627992bf-6142-4411-d658-f7183bbbb257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score :  [[1.         0.56450027]\n",
            " [0.56450027 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the percentage\n",
        "matchpercentage = cosine_similarity(count_matrix)[0][1]\n",
        "matchpercentage = round(float(matchpercentage)*100,4)\n",
        "print('Your Resume {} % matched  of the job-description!'.format(matchpercentage))\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dDBYQ9Wb62l",
        "outputId": "ec778d26-4628-4ce3-b812-5a451123d388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Resume 56.45 % matched  of the job-description!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMQzN5PrcDdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}